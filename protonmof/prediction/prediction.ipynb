{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6615704-80e8-493d-8afe-f100cfbbb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from glob import glob\n",
    "from moftransformer.utils import prepare_data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import functools\n",
    "from typing import Optional\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from moftransformer.datamodules.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import copy\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pytorch_lightning as pl\n",
    "from moftransformer.config import ex\n",
    "from moftransformer.config import config as _config\n",
    "from moftransformer.datamodules.datamodule import Datamodule\n",
    "from moftransformer.modules.module import Module\n",
    "from moftransformer.utils.validation import (\n",
    "    get_valid_config,\n",
    "    get_num_devices,\n",
    "    ConfigurationError,\n",
    ")\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from protonmof.model.model import MOFProtonModel\n",
    "from protonmof.data.dataset_finetune import MOFProtonDataset\n",
    "from protonmof.utils import split_by_cif, Normalizer, calculate_con\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", \".*Trying to infer the `batch_size` from an ambiguous collection.*\"\n",
    ")\n",
    "\n",
    "_IS_INTERACTIVE = hasattr(sys, \"ps1\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc33d3-6911-4fc2-83d4-3809d09aa563",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cif_dir = 'cif/'\n",
    "cif_names = ['RIMROX']\n",
    "target_guest_smiles = ['CN(C)CO']\n",
    "target_guest_names = ['DMF']\n",
    "T, RH = [298], [98]\n",
    "\n",
    "ckpt_dir = '../ckpt/best.ckpt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af6138c-6655-49eb-a5b0-055f126865ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_data = pd.DataFrame({'Name': cif_names, \n",
    "              'Temperature': T, \n",
    "              'RH': RH, \n",
    "              'Guest': target_guest_names,\n",
    "             'proton conductivity': [0 for _ in range(len(cif_names))]})\n",
    "#exp_data.to_csv('exp_data.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f25064d-9804-4a12-90e4-368708f0dede",
   "metadata": {},
   "source": [
    "### MOFTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5579aa2-7431-43d9-925f-1ebcc561fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0\n",
    "test_fraction = 1 \n",
    "target_data_dir = 'target'\n",
    "try:\n",
    "    prepare_data(target_cif_dir, target_data_dir,  downstream='example',\n",
    "                 train_fraction=train_fraction, test_fraction=test_fraction)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d89ac2b-9514-440a-add4-f5f2fb3e2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "cif_tmp_json = {cif[:-5]: 1 for cif in os.listdir(f'{target_data_dir}/test/') if cif.endswith('grid')}\n",
    "with open(f'{target_data_dir}/test.json', 'w') as f:\n",
    "    json.dump(cif_tmp_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b425b26-b159-4ec3-960b-3e1a1652875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moftransformer.config import config as _config\n",
    "downstream=None\n",
    "log_dir=\"logs/\"\n",
    "test_only=True\n",
    "\n",
    "config = copy.deepcopy(_config())\n",
    "# for key in kwargs.keys():\n",
    "#     if key not in config:\n",
    "#         raise ConfigurationError(f\"{key} is not in configuration.\")\n",
    "\n",
    "# config.update(kwargs)\n",
    "config[\"root_dataset\"] = f'{target_data_dir}/'\n",
    "config[\"downstream\"] = ''\n",
    "config[\"log_dir\"] = log_dir\n",
    "config[\"test_only\"] = test_only\n",
    "config['load_path']='/home/seunghh/anaconda3/envs/protonmof/lib/python3.8/site-packages/moftransformer/database/moftransformer.ckpt'\n",
    "_config = config\n",
    "_config = copy.deepcopy(_config)\n",
    "pl.seed_everything(_config[\"seed\"])\n",
    "\n",
    "_config = get_valid_config(_config)\n",
    "\n",
    "dm = Datamodule(_config)\n",
    "model = Module(_config)\n",
    "exp_name = f\"{_config['exp_name']}\"\n",
    "dm.setup(stage='test')\n",
    "dataloader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e325a-65c7-4545-b59a-e666cae903dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "all_features= []\n",
    "cif_ids = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        output = model(batch)\n",
    "        features = output['cls_feats']\n",
    "        all_features.append(features.detach().numpy())\n",
    "        cif_ids += (batch['cif_id'])\n",
    "\n",
    "    all_features = np.concatenate(all_features)\n",
    "\n",
    "mof_desc_dict={ids : feat for ids, feat in zip(cif_ids, all_features)}\n",
    "mof_desc_dict = {key: value.tolist() for key, value in mof_desc_dict.items()}\n",
    "with open('./mof_features_eval.json', 'w') as f:\n",
    "    json.dump(mof_desc_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2278959-34f5-45ab-8671-f63ab0f18b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d066a949-2cb9-4993-a859-5feb2688d84b",
   "metadata": {},
   "source": [
    "### ChemBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ac54b2-6f12-4123-9c34-610d786cbef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembert = ClassificationModel('roberta', 'seyonec/PubChem10M_SMILES_BPE_396_250', \n",
    "                            num_labels=1,\n",
    "                            args={'evaluate_each_epoch': True, \n",
    "                                  'evaluate_during_training_verbose': True,\n",
    "                                  'no_save': False, 'num_train_epochs': 10, \n",
    "                                  'regression' : True,\n",
    "                                  'auto_weights': True}) # You can set class weights by using the optional weight argument\n",
    "model = chembert.model\n",
    "tokens = chembert.tokenizer(target_guest_smiles, add_special_tokens=True, truncation=True, \n",
    "                                 max_length=256, padding=\"max_length\", \n",
    "                              return_tensors='pt',\n",
    "                              return_offsets_mapping=False)\n",
    "for k, v in tokens.items():\n",
    "    tokens[k] = torch.tensor(v, dtype=torch.long,).to(model.device)  \n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs=model.roberta(tokens['input_ids'], tokens['attention_mask'])[0][:,0,:]\n",
    "    outputs = outputs.detach().numpy()\n",
    "\n",
    "smiles_feat = {name: feat.tolist() for name, feat in zip(target_guest_names, outputs)}\n",
    "\n",
    "with open('guest_features_eval.json', 'w') as json_file:\n",
    "    json.dump(smiles_feat, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29fbc8-d39c-4208-96be-2f9b4ce44c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a6e3b-37a9-426c-b45a-d63cb4201056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e074c-d649-46c4-a5fd-53b73f549314",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml', 'r') as f:\n",
    "    config = EasyDict(yaml.safe_load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601811e0-1f33-4e9e-9b8a-181855ba3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_scaler = Normalizer(mean = config.dataset.mean, std = config.dataset.std)\n",
    "t_scaler = Normalizer(mean = config.dataset.t_mean, std = config.dataset.t_std)\n",
    "rh_scaler = Normalizer(mean = config.dataset.rh_mean, std = config.dataset.rh_std)\n",
    "proton_model = MOFProtonModel.load_from_checkpoint(ckpt_dir,  config=config, scaler = prop_scaler,  strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed82cec-201a-47b3-83ff-877b41d22e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_data = MOFProtonDataset(proton_data = exp_data,\n",
    "                         config=config,\n",
    "                             scaler = prop_scaler,\n",
    "                         t_scaler = t_scaler,\n",
    "                         rh_scaler = rh_scaler,\n",
    "                             \n",
    "                          )\n",
    "\n",
    "test_loader =DataLoader(test_data, 1 , num_workers = config.train.num_workers, \n",
    "                         shuffle=False)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fb2d72-8ad5-4549-a2b7-3d58b1db5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_con_pred = []\n",
    "proton_model.eval()\n",
    "for batch in test_loader:\n",
    "    output  = proton_model(batch)\n",
    "    con_pred = calculate_con(output, batch, proton_model.arr)\n",
    "    pred = con_pred.cpu().tolist()\n",
    "    all_con_pred += list(np.array(pred).reshape(-1))\n",
    "    \n",
    "all_con_pred = proton_model.scaler.decode(np.array(all_con_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ed23d5-53b3-4f49-be09-ae04c5e43d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_con_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b666088e-b502-4ef8-afbc-7c63b74389da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Proton Conductivity (predicted): {all_con_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca78bf-a72a-4e2c-bfd3-bcf2f9d9f4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
